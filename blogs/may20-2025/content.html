<head>
    <title>
        May 20, 2025: Exploring the CUDA software architecture
    </title>
    <link id="css" rel="stylesheet" href="../../styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link id="font_control" href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@300&family=Open+Sans:wght@300;400&family=Turret+Road:wght@700&display=swap" rel="stylesheet">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="module" src="https://md-block.verou.me/md-block.js"></script>
    
    <style>
        .codeblock {
            padding:20px;
            color:#faffb1;
            background-color:#222;
        }
    </style>
</head>
<body>
    <div id="main_div" class="row">
        <div class="column">
            <a href="../../index.html">Back</a>
            <h2>
                May 20, 2025
            </h2>
            <md-block>
                CUDA is a suite of hardware and software technologies developed by NVIDIA for their GPUs. It is one of the most
                consequential technologies in modern computing, acting as the bedrock for data parallel workloads present in
                machine learning, scientific computing, and more. In this blog, I want to share my understanding of the systems
                software that enables CUDA. Note that this discussion will be targeted to Linux, although I would guess
                the same ideas apply to Windows.

                The CUDA software architecture can be broken into two parts: The kernel drivers and the user-space CUDA toolkit. The CUDA toolkit
                is by far the more transparent part of the system: with public NVIDIA docs and the trusty `readelf` and `objdump`
                tools in Linux, a lot can be learned about it. Broadly, the CUDA toolkit contains all of the user-space utilities needed for
                CUDA support, such as the `nvcc` compiler, the runtime libraries `libcudart.so` and `cuda.so`, algorithm libraries such as
                cuBLAS, cuSPARSE, cuDNN, etc. and more.

                The kernel driver is required for communication with the device. Information about this is scarce, so much of what I write
                here is speculation based on my knowledge from working at NVIDIA. As I understand, the role of the kernel driver should be
                to allocate and export command buffers for user-space to issue device commands, and to facilitate host-device memory transfers.
                From user-space's perspective, the interface to these functions are IOCTLs to a device node, located in `/dev`, that is defined and exported
                by the driver's kernel module. Head-ful (i.e. with display) systems with NVIDIA have the `nvidia`, `nvidia-modeset`, `nvidia-drm`,
                and `nvidia-uvm` modules. `nvidia-modeset` and `nvidia-drm` are display/graphics specific (what I work on!), and `nvidia` is a generic resource
                management layer. In the graphics stack, this is used by user software like the X driver and OpenGL/Vulkan to manage frame/command buffers, along
                with parts of the kernel drivers to do e.g. modesetting. I'm assuming CUDA probably uses it too.
                Data exchange with the GPU is done with DMA: The driver must allocate a region of low-memory (i.e. that which is permanently, directly mapped
                and cannot be paged) and use the functions in `<linux/dma-mapping.h>` to generate a device-accessible address to it. Users can then obtain
                access to the DMA region via `mmap`, or the more sophisticated DMA-BUF mechanism in recent kernels.
                
                <code class="codeblock">
                    // Sample code
                </code>
            </md-block>
        </div>
    </div>
</body>
